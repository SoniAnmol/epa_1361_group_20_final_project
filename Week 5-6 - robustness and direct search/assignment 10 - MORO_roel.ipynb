{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-objective Robust Optimization (MORO)\n",
    "\n",
    "\n",
    "This exercise demostrates the application of MORO on the lake model. In contrast to the exercises in previous weeks, we will be using a slightly more sophisticated version of the problem. For details see the MORDM assignment for this week.\n",
    "\n",
    "## Setup MORO\n",
    "\n",
    "Many objective robust optimization aims at finding decisions that are robust with respect to the various deeply uncertain factors. For this, MORO evalues each candidate decision over a set of scenarios. For each outcome of interest, the robusntess over this set is calculated. A MOEA is used to maximize the robustness. \n",
    "\n",
    "For this assignment, we will be using a domain criterion as our robustness metric. The table below lists the rules that you should use for each outcome of interest.\n",
    "\n",
    "|Outcome of interest| threhsold  |\n",
    "|-------------------|------------|\n",
    "| Maximum pollution | $\\leq$ 0.75|\n",
    "| Inertia           | $\\geq$ 0.6 |\n",
    "| Reliability       | $\\geq$ 0.99|   \n",
    "| Utility           | $\\geq$ 0.75|\n",
    "\n",
    "**1) Implement a function for each outcome that takes a numpy array with results for the outcome of interest, and returns the robustness score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lakemodel_function import lake_problem\n",
    "from ema_workbench import (RealParameter, ScalarOutcome, Constant,\n",
    "                           Model)\n",
    "import pandas as pd\n",
    "from ema_workbench.analysis import prim\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "from ema_workbench import MultiprocessingEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "def robustness(direction, threshold, data):\n",
    "    if direction == SMALLER:\n",
    "        return np.sum(data<=threshold)/data.shape[0]\n",
    "    else:\n",
    "        return np.sum(data>=threshold)/data.shape[0]\n",
    "\n",
    "def maxp(data):\n",
    "    return np.sum(data<=0.75)/data.shape[0]\n",
    "    \n",
    "SMALLER = 'SMALLER'\n",
    "LARGER = 'LARGER'\n",
    "\n",
    "maxp = functools.partial(robustness, SMALLER, 0.75)\n",
    "inertia = functools.partial(robustness, LARGER, 0.6)\n",
    "reliability = functools.partial(robustness, LARGER, 0.99)\n",
    "utility = functools.partial(robustness, LARGER, 0.75)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functools.partial(<function robustness at 0x000001BE2F2314C0>, 'SMALLER', 0.75)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dps lake model\n",
    "from dps_lake_model import lake_model\n",
    "\n",
    "from ema_workbench import (Model, RealParameter, ScalarOutcome,\n",
    "                           MultiprocessingEvaluator, ema_logging,\n",
    "                           Constant)\n",
    "\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "#instantiate the model\n",
    "lake_model = Model('lakeproblem', function=lake_model)\n",
    "lake_model.time_horizon = 100 # used to specify the number of timesteps\n",
    "\n",
    "#specify uncertainties\n",
    "lake_model.uncertainties = [RealParameter('mean', 0.01, 0.05),\n",
    "                            RealParameter('stdev', 0.001, 0.005),\n",
    "                            RealParameter('b', 0.1, 0.45),\n",
    "                            RealParameter('q', 2.0, 4.5),\n",
    "                            RealParameter('delta', 0.93, 0.99)]\n",
    "\n",
    "# set levers\n",
    "lake_model.levers = [RealParameter(\"c1\", -2, 2),\n",
    "                RealParameter(\"c2\", -2, 2),\n",
    "                RealParameter(\"r1\", 0, 2),\n",
    "                RealParameter(\"r2\", 0, 2),\n",
    "                RealParameter(\"w1\", 0, 1)]\n",
    "\n",
    "#specify outcomes \n",
    "lake_model.outcomes = [ScalarOutcome('max_P', kind=ScalarOutcome.MINIMIZE),\n",
    "                       ScalarOutcome('utility', kind=ScalarOutcome.MAXIMIZE),\n",
    "                       ScalarOutcome('inertia', kind=ScalarOutcome.MINIMIZE),\n",
    "                       ScalarOutcome('reliability', kind=ScalarOutcome.MAXIMIZE)]\n",
    "\n",
    "\n",
    "lake_model.constantcs = [Constant('alpha', 0.41),\n",
    "                         Constant('reps', 150)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Generate 4 random release policies, and evaluate them over 500 scenarios. Sample the scenarios using Monte Carlo sampling. Next evaulate your robustness function for 1, 2, 3, ... 500 scenarios for each outcome and visualize this. What can you tell about the convergernce of the robusntess metric as a function of the number of scenarios?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] pool started\n",
      "[MainProcess/INFO] performing 500 scenarios * 4 policies * 1 model(s) = 2000 experiments\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] 1200 cases completed\n",
      "[MainProcess/INFO] 1400 cases completed\n",
      "[MainProcess/INFO] 1600 cases completed\n",
      "[MainProcess/INFO] 1800 cases completed\n",
      "[MainProcess/INFO] 2000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] terminating pool\n"
     ]
    }
   ],
   "source": [
    "#ema_workbench.em_framework.samplers.MonteCarloSampler\n",
    "\n",
    "n_scenarios = 500\n",
    "n_policies = 4\n",
    "\n",
    "with MultiprocessingEvaluator(lake_model) as evaluator:\n",
    "    experiments, outcomes = evaluator.perform_experiments(n_scenarios, n_policies, uncertainty_sampling=\"mc\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>delta</th>\n",
       "      <th>mean</th>\n",
       "      <th>q</th>\n",
       "      <th>stdev</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>w1</th>\n",
       "      <th>scenario</th>\n",
       "      <th>policy</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.128935</td>\n",
       "      <td>0.973116</td>\n",
       "      <td>0.025252</td>\n",
       "      <td>3.711260</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>0.812577</td>\n",
       "      <td>-1.942103</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.645131</td>\n",
       "      <td>0.737354</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>lakeproblem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.261266</td>\n",
       "      <td>0.961104</td>\n",
       "      <td>0.046462</td>\n",
       "      <td>3.620558</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.812577</td>\n",
       "      <td>-1.942103</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.645131</td>\n",
       "      <td>0.737354</td>\n",
       "      <td>501</td>\n",
       "      <td>4</td>\n",
       "      <td>lakeproblem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.169584</td>\n",
       "      <td>0.984581</td>\n",
       "      <td>0.027315</td>\n",
       "      <td>2.520626</td>\n",
       "      <td>0.003171</td>\n",
       "      <td>0.812577</td>\n",
       "      <td>-1.942103</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.645131</td>\n",
       "      <td>0.737354</td>\n",
       "      <td>502</td>\n",
       "      <td>4</td>\n",
       "      <td>lakeproblem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.435228</td>\n",
       "      <td>0.984582</td>\n",
       "      <td>0.017338</td>\n",
       "      <td>2.600824</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>0.812577</td>\n",
       "      <td>-1.942103</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.645131</td>\n",
       "      <td>0.737354</td>\n",
       "      <td>503</td>\n",
       "      <td>4</td>\n",
       "      <td>lakeproblem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.144509</td>\n",
       "      <td>0.942019</td>\n",
       "      <td>0.034404</td>\n",
       "      <td>3.278141</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>0.812577</td>\n",
       "      <td>-1.942103</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.645131</td>\n",
       "      <td>0.737354</td>\n",
       "      <td>504</td>\n",
       "      <td>4</td>\n",
       "      <td>lakeproblem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.439913</td>\n",
       "      <td>0.970865</td>\n",
       "      <td>0.032442</td>\n",
       "      <td>3.763258</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>1.050075</td>\n",
       "      <td>1.241153</td>\n",
       "      <td>0.631499</td>\n",
       "      <td>1.556131</td>\n",
       "      <td>0.890242</td>\n",
       "      <td>995</td>\n",
       "      <td>7</td>\n",
       "      <td>lakeproblem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.329139</td>\n",
       "      <td>0.958996</td>\n",
       "      <td>0.011686</td>\n",
       "      <td>4.394198</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>1.050075</td>\n",
       "      <td>1.241153</td>\n",
       "      <td>0.631499</td>\n",
       "      <td>1.556131</td>\n",
       "      <td>0.890242</td>\n",
       "      <td>996</td>\n",
       "      <td>7</td>\n",
       "      <td>lakeproblem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.238016</td>\n",
       "      <td>0.955845</td>\n",
       "      <td>0.043699</td>\n",
       "      <td>3.598103</td>\n",
       "      <td>0.003123</td>\n",
       "      <td>1.050075</td>\n",
       "      <td>1.241153</td>\n",
       "      <td>0.631499</td>\n",
       "      <td>1.556131</td>\n",
       "      <td>0.890242</td>\n",
       "      <td>997</td>\n",
       "      <td>7</td>\n",
       "      <td>lakeproblem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.224052</td>\n",
       "      <td>0.948103</td>\n",
       "      <td>0.023428</td>\n",
       "      <td>4.320104</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>1.050075</td>\n",
       "      <td>1.241153</td>\n",
       "      <td>0.631499</td>\n",
       "      <td>1.556131</td>\n",
       "      <td>0.890242</td>\n",
       "      <td>998</td>\n",
       "      <td>7</td>\n",
       "      <td>lakeproblem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.258877</td>\n",
       "      <td>0.973285</td>\n",
       "      <td>0.032591</td>\n",
       "      <td>3.082002</td>\n",
       "      <td>0.004028</td>\n",
       "      <td>1.050075</td>\n",
       "      <td>1.241153</td>\n",
       "      <td>0.631499</td>\n",
       "      <td>1.556131</td>\n",
       "      <td>0.890242</td>\n",
       "      <td>999</td>\n",
       "      <td>7</td>\n",
       "      <td>lakeproblem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             b     delta      mean         q     stdev        c1        c2  \\\n",
       "0     0.128935  0.973116  0.025252  3.711260  0.002315  0.812577 -1.942103   \n",
       "1     0.261266  0.961104  0.046462  3.620558  0.003652  0.812577 -1.942103   \n",
       "2     0.169584  0.984581  0.027315  2.520626  0.003171  0.812577 -1.942103   \n",
       "3     0.435228  0.984582  0.017338  2.600824  0.002726  0.812577 -1.942103   \n",
       "4     0.144509  0.942019  0.034404  3.278141  0.001372  0.812577 -1.942103   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1995  0.439913  0.970865  0.032442  3.763258  0.003451  1.050075  1.241153   \n",
       "1996  0.329139  0.958996  0.011686  4.394198  0.002417  1.050075  1.241153   \n",
       "1997  0.238016  0.955845  0.043699  3.598103  0.003123  1.050075  1.241153   \n",
       "1998  0.224052  0.948103  0.023428  4.320104  0.001864  1.050075  1.241153   \n",
       "1999  0.258877  0.973285  0.032591  3.082002  0.004028  1.050075  1.241153   \n",
       "\n",
       "            r1        r2        w1 scenario policy        model  \n",
       "0     0.000995  0.645131  0.737354      500      4  lakeproblem  \n",
       "1     0.000995  0.645131  0.737354      501      4  lakeproblem  \n",
       "2     0.000995  0.645131  0.737354      502      4  lakeproblem  \n",
       "3     0.000995  0.645131  0.737354      503      4  lakeproblem  \n",
       "4     0.000995  0.645131  0.737354      504      4  lakeproblem  \n",
       "...        ...       ...       ...      ...    ...          ...  \n",
       "1995  0.631499  1.556131  0.890242      995      7  lakeproblem  \n",
       "1996  0.631499  1.556131  0.890242      996      7  lakeproblem  \n",
       "1997  0.631499  1.556131  0.890242      997      7  lakeproblem  \n",
       "1998  0.631499  1.556131  0.890242      998      7  lakeproblem  \n",
       "1999  0.631499  1.556131  0.890242      999      7  lakeproblem  \n",
       "\n",
       "[2000 rows x 13 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_P': array([8.72559128, 4.3709673 , 6.59830497, ..., 4.79122839, 5.01020558,\n",
       "        4.33460722]),\n",
       " 'utility': array([1.39035977, 1.00891095, 2.04573015, ..., 0.85571781, 0.72618327,\n",
       "        1.34303286]),\n",
       " 'inertia': array([0.99  , 0.99  , 0.99  , ..., 0.9711, 0.9769, 0.9795]),\n",
       " 'reliability': array([0.05  , 0.07  , 0.03  , ..., 0.0619, 0.0967, 0.0611])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for candidate solutions\n",
    "Set up the robust optimization problem using the robustness functions you have specified. Assume that you will need 50 scenarios for estimating the robustness. Use $\\epsilon$-progress and hypervolume to track convergence. Solve the optimization problem. As $\\epsilon$ values, you can assume 0.05 for each of the four robustness metrics.\n",
    "\n",
    "*note: this optimization problem is computationally very expensive. Develop and test your code using a sequential evaluator, a low number of function evaluations (e.g., 200), and a low number of scenarios (e.g., 5). Once everything seems to be working replace the sequential evaluator with an multiprocessing or ipyparallel evaluator, and increase the number of nfe and scenarios*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot your $\\epsilon$-progress to evaluate convergergence, and visualize the trade-offs using parallel coordinate plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What does this plot tell us about the tradeoffs and conflicting objectives?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-evaluate candidate solutions under uncertainty\n",
    "\n",
    "We have used only 50 scenarios for the optimization. Take the results and re-evaluate them over a larger set (assume 1000 scenarios). How different are your results? What does this imply for the assumption of 50 scenarios during robust optimization.\n",
    "\n",
    "*hint: use the to_dict method on a dataframe, next generate Policy objects in a list expression by iterating over the dicts returned by the to_dict method*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison\n",
    "If you have time, import your solutions found for MORDM and re-evaluate them over the same set of scnearios as used for re-evaluating the MORO results. Compare the robustness of MORDM and MORO, what do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
