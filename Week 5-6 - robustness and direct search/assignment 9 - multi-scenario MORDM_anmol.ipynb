{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Scenario MORDM\n",
    "\n",
    "Multi-scenario MORMD is an extension of normal MORDM to better include robustness considerations within the search phase. It starts from the scenario discovery results resulting from MORDM. Next, from the experiments within this box, a set of scenarios is selected. \n",
    "\n",
    "There are many ways of selecting the additional scenarios. The original paper which introduced multi-scenario MORMD [Watson and Kaspzryk (2017)](https://doi.org/10.1016/j.envsoft.2016.12.001) did it in a more or less adhoc manner. [Eker and Kwakkel (2018)](https://doi.org/10.1016/j.envsoft.2018.03.029) introduced a more formal selection approach, the code of which can be found on [GitHub](https://github.com/sibeleker/MORDM---Multi-scenario-search). \n",
    "\n",
    "For this assignment, make an informed selection of 4 scenarios, using an approach of your choice. Motivate carefully your selection procedure. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the results file\n",
    "from ema_workbench import load_results\n",
    "file_name = 'selected_results.tar.gz'\n",
    "results = load_results(file_name)\n",
    "# Extracting experiment and outcomes from results\n",
    "exp, outcomes = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normailze the dictionary outcomes\n",
    "def normalize_out_dic(outcomes):\n",
    "    norm_outcomes = {}\n",
    "    for ooi in outcomes.keys():\n",
    "        data = outcomes[ooi]\n",
    "        mx = max(data)\n",
    "        mn = min(data)\n",
    "        if mx == mn:\n",
    "            norm_outcomes[ooi] = data - mn\n",
    "        else:\n",
    "            norm_outcomes[ooi] = (data - mn)/(mx-mn)\n",
    "    return norm_outcomes\n",
    "\n",
    "\n",
    "# Defining function for calculating distance and diversity of scenarios\n",
    "def calculate_distance(data, oois, scenarios=None, distance='euclidean'):\n",
    "    '''data is the outcomes of exploration results,\n",
    "    scenarios is a list of scenario indices (decision variables), \n",
    "    oois is a list of variable names,\n",
    "    distance is to choose the distance metric. options:\n",
    "            bray-curtis, canberra, chebyshev, cityblock (manhattan), correlation, \n",
    "            cosine, euclidian, mahalanobis, minkowski, seuclidian,\n",
    "            sqeuclidian, wminkowski\n",
    "    returns a list of distance values\n",
    "    '''\n",
    "    #make a matrix of the data n_scenarios x oois\n",
    "    scenario_data = np.zeros((len(scenarios), len(oois)))\n",
    "    for i, s in enumerate(scenarios):\n",
    "        for j, ooi in enumerate(oois):\n",
    "            scenario_data[i][j] = data[ooi][s]\n",
    "                \n",
    "    distances = pdist(scenario_data, distance)\n",
    "    return distances\n",
    "\n",
    "# Function for calculating unique diversity \n",
    "def evaluate_diversity_single(x, data=norm_new_out, oois=oois, weight=0.5, distance='euclidean'):\n",
    "    '''\n",
    "    takes the outcomes and selected scenario set (decision variables), \n",
    "    returns a single 'diversity' value for the scenario set.\n",
    "    outcomes : outcomes dictionary of the scenario ensemble\n",
    "    decision vars : indices of the scenario set\n",
    "    weight : weight given to the mean in the diversity metric. If 0, only minimum; if 1, only mean\n",
    "    '''\n",
    "    distances = calculate_distance(data, oois, list(x), distance)\n",
    "    minimum = np.min(distances)\n",
    "    mean = np.mean(distances)\n",
    "    diversity = (1-weight)*minimum + weight*mean\n",
    "    \n",
    "    return [diversity]\n",
    "\n",
    "# Function for finding maximum diverse scenarios\n",
    "def find_maxdiverse_scenarios(combinations):\n",
    "    diversity = 0.0\n",
    "    solutions = []\n",
    "    for sc_set in combinations:\n",
    "        temp_div = evaluate_diversity_single(list(sc_set))\n",
    "        if temp_div[0] > diversity:\n",
    "            diversity = temp_div[0]\n",
    "            solutions = []\n",
    "            solutions.append(sc_set)\n",
    "        elif temp_div[0] == diversity:\n",
    "            solutions.append(sc_set)\n",
    "    #print(\"found diversity \", diversity)\n",
    "    return diversity, solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normailizing the outcomes\n",
    "norm_new_out = normalize_out_dic(outcomes)\n",
    "\n",
    "# creating a list of outcome variables (key of dictionary)\n",
    "oois = list(outcomes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of scenarios = total number of unique outcome variables\n",
    "n_scen = len(outcomes[oois[0]])\n",
    "indices = range(n_scen)\n",
    "set_size = 4\n",
    "import itertools\n",
    "# Making all the possible combinations of number of scenarios for desired number\n",
    "combinations = itertools.combinations(indices, set_size)\n",
    "# changing the type\n",
    "combinations = list(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_workers = multiprocessing.cpu_count()\n",
    "    pool = multiprocessing.Pool(processes=no_workers)\n",
    "    \n",
    "    with open('output_scenarioselection_v3.txt', 'a') as file:\n",
    "    \n",
    "        start_time = time.time()\n",
    "        #now, divide this data for each worker\n",
    "        worker_data = np.array_split(combinations, no_workers)\n",
    "               \n",
    "        result = pool.imap(find_maxdiverse_scenarios, worker_data)\n",
    "                \n",
    "        #find the max of these 8 \n",
    "        max_diversity = 0.0\n",
    "        for r in result:\n",
    "            print(\"result : \", r)\n",
    "            if r[0] >= max_diversity:\n",
    "                max_diversity = r[0]\n",
    "                solutions = []\n",
    "                solutions.append(r[1])\n",
    "            elif r[0] == max_diversity:\n",
    "                solutions.append(r[1])                  \n",
    "  \n",
    "        end_time = time.time()\n",
    "        file.write(\"Calculations took {} seconds.\\n\".format(end_time-start_time))\n",
    "        print(\"Calculations took {} seconds.\\n\".format(end_time-start_time))\n",
    "        file.write(\"maximum diversity and solutions: {}, {} \\n\\n\".format(max_diversity, solutions))\n",
    "        print(\"maximum diversity and solutions: {}, {} \\n\\n\".format(max_diversity, solutions))\n",
    "\n",
    "\n",
    "    file.close()\n",
    "        \n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for each scenario\n",
    "\n",
    "For each of the four selected scenarios, use many-objective optimization to find a pareto approximate set using the same approach as for assignment 8. Remember to check for convergence (and time permitting, seed analysis), and be careful in what epsilon values to use (not to coarse, not too small). \n",
    "\n",
    "Store the resulting set of pareto solutions in a smart way for subsequent analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-evaluate under deep uncertainty\n",
    "\n",
    "Combine the pareto set of solutions found for each scenario. Next, turn each solution into a policy object. If you have a very large number of policies, you can choose to down sample your policies in some reasoned way (*e.g.*, picking min and max on each objective, slicing across the pareto front with a particular step size). As a rule of thumb, try to limit the set of policies to at most 50. \n",
    "\n",
    "Re-evaluate the combined set of solutions over 1000 scenarios sampled using LHS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate both the maximum regret, and the domain criterion using the values provided in [Bartholomew and Kwakkel (2020)](https://doi.org/10.1016/j.envsoft.2020.104699). Ignore the max_P objective.\n",
    "\n",
    "visualize the results in parallel coordinate plot. \n",
    "\n",
    "Are there any promising compromise solutions which balance performance in both the reference scenarios as well as in terms of their robustness?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "name": "python382jvsc74a57bd0816b03353e7e365ebca7eda07c63a8cdb1e4e8d8dcf7a6280da8b1a7716a1567",
   "display_name": "Python 3.8.2 64-bit ('epa1361': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}